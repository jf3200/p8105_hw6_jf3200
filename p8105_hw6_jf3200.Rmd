---
title: "Homework 6"
author: "Jessica Flynn"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r load_package_and_settings}
library(tidyverse)
library(p8105.datasets)
library(modelr)
library(gtsummary)

set.seed(1)


theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
  )
```


## Problem 1 

```{r import_and_clean_homicide_data}
homicide_df = 
  read_csv("data/homicide-data.csv", na = c("", "NA", "Unknown")) %>% 
  mutate( 
    city_state = str_c(city, state, sep = "_"),
    victim_age = as.numeric(victim_age),
    resolved = case_when(
      disposition == "Closed without arrest" ~ 0, 
      disposition =="Open/No arrest" ~ 0, 
      disposition == "Closed by arrest" ~ 1)) %>%
  filter(victim_race %in% c("White", "Black"),
         city_state != "Tulsa_AL", 
         city_state != "Dallas_TX", 
         city_state != "Phoenix_AZ", 
         city_state != "Kansas City_MO") %>%
  select(city_state, resolved, victim_age, victim_race, victim_sex)
```

Start with one city.

```{r baltimore_example}
baltimore_df = 
  homicide_df %>% 
  filter(city_state == "Baltimore_MD")


baltimore_model = 
  glm(resolved ~ victim_age + victim_race + victim_sex,
    data = baltimore_df, 
    family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(
    OR = exp(estimate), 
    CI_lower = exp(estimate - 1.96*std.error), 
    CI_upper = exp(estimate + 1.96*std.error)) %>% 
  select(term, OR, starts_with("CI"))

baltimore_model %>% 
  knitr::kable(digits = 3)

```

The  estimate of the adjusted odds ratio for solving homicides comparing non-white victims to white victims keeping all other variables fixed is `r round(baltimore_model %>% filter(term == "victim_raceWhite") %>% pull(OR),3)` and the confidence interval is (`r round(baltimore_model %>% filter(term == "victim_raceWhite") %>% pull(CI_lower),3)`, `r round(baltimore_model %>% filter(term == "victim_raceWhite") %>% pull(CI_upper), 3)`)

Try this across cities.

```{r map_across_cities}
model_results_df =
  homicide_df %>% 
  nest(data = -city_state) %>% 
  mutate(models = map(.x = data, ~glm(resolved ~ victim_age + victim_race + victim_sex, data = .x, family = binomial())), 
         results = map(models, broom::tidy)) %>% 
  select(city_state, results) %>% 
  unnest(results) %>% 
  mutate(
    OR = exp(estimate), 
    CI_lower = exp(estimate - 1.96*std.error), 
    CI_upper = exp(estimate + 1.96*std.error)) %>% 
  select(city_state, term, OR, starts_with("CI")) %>% 
  print()
```

```{r estimate_plot}
model_results_df %>% 
  filter(term == "victim_raceWhite") %>%
  mutate(city_state = fct_reorder(city_state, OR)) %>%
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) +
  theme(axis.text.x =  element_text(angle = 90, vjust = 0.5, hjust = 1))
```

This plot shows that for all cities, the OR is above 1 for the odds of solving homicides for white victims compared to black victims. In Boston, MA, this OR is the largest with the odds of a crime being solved for a white victim at over 10 times the odds of it being solves for a black victim.

## Problem 2

```{r import_clean_birthweight_data}
birth_df = 
  read_csv("data/birthweight.csv", na = c("", "NA", "Unknown")) %>% 
  mutate(babysex = case_when(babysex == 1 ~ "male", 
                             babysex == 2 ~ "female"), 
         malform = case_when(malform == 0 ~ "absent", 
                             malform == 1 ~ "present")) %>% 
  mutate_at(
    vars(contains("race")), 
    funs(case_when(
      . == 1 ~ "white", 
      . == 2 ~"black", 
      . == 3 ~ "asian",
      . == 4 ~ "puerto rican", 
      . == 8 ~ "other", 
      . == 9 ~ "unknown")))

```

Next, we will build a model to predict `bwt`, the child's birthweight. The first step in this modeling process will be to look at which variables alone are significant predictors of birthweight. This is referred to as univariable analysis. We will conduct this for all variables and use `bwt` as the outcome.

```{r uva}
tbl_uvregression(birth_df, 
                 method = lm, 
                 y = bwt)

```

From the univariable analysis, we see that many variables are significant predictors of bwt. A few of these variables are likely to be highly correlated. For example, `ppbmi` (mother's pre-pregnancy BMI) and `ppwt` (mother's pre-pregnancy weight) and are similar measures, Additionally, `delwt`(mother's weight at delivery) is likely highly correlated with `ppbmi`, as is `mheight`(mother's height). Delivery weight is also likely correlated with `ppwt` and `wtgain`(mother's weight gain during pregnancy). 

Since `ppbmi` has height and weight information, we will use only this and not all of the potentially correlated variables (`ppwt`, `delwt`, `mheight`, `wtgain`)  

`pnumlbw` and `pnumsga` are both columns of all 0 values, so not beta was able to be estimated. 

Since only Black vs Asian is significant for both `mrace` and `frace` and all levels are not significant, we will not include these variables in the multivariable model.

Now, we will put all of the remaining significant variables into a multivariable model. 
```{r mva}
model_multi = lm(bwt ~ babysex + bhead + blength + fincome  + gaweeks  + momage  + ppbmi + smoken, data = birth_df)

model_multi %>% 
  broom::tidy() %>% 
  knitr::kable()
```


All of the variables in our model are independently significant predictions of baby's birthweight. Now, we will plot of fitted values vs residuals. Below, we see that the majority of the resdiuals hover around 0, and that there is no obvious pattern in the residuals, however, there are some extreme residuals which may be a concern. 

```{r fitted_resid_plot}
birth_df %>% 
  add_residuals(model_multi) %>% 
  add_predictions(model_multi) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() + 
  labs(x = "Fitted Values", 
         y = "Residuals")
```

Model comparison using `crossv_mc` for cross validation

```{r  compare_plots}
model_main = lm(bwt ~ blength + gaweeks, data = birth_df)
model_interaction = lm(bwt ~ bhead * blength * babysex, data = birth_df)

cv_df = 
  crossv_mc(birth_df, 100) 

cv_df =
  cv_df %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df = 
  cv_df %>% 
  mutate(
    model_main  = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    model_interaction = map(train, ~lm(bwt ~ bhead * blength * babysex, data = .x)),
    model_multi  = map(train, ~lm(bwt~ babysex + bhead + blength + fincome  + gaweeks  + momage  + ppbmi + smoken, data = .x))) %>% 
  mutate(
    rmse_main = map2_dbl(model_main, test, ~rmse(model = .x, data = .y)),
    rmse_interaction = map2_dbl(model_interaction, test, ~rmse(model = .x, data = .y)),
    rmse_multi = map2_dbl(model_multi, test, ~rmse(model = .x, data = .y)))

```


Compare RSMEs 

```{r plot_rsme}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin()
```

Looking at the RSME plot, we see that the model with the lowest RMSE is the model we created, although, it may not have a sigificantly lower RMSE than the interaction model. We would have to think carefully about which model to choose -- the interaciton model is more complicated to interpret, but our model has more covariates. 

## Problem 3

